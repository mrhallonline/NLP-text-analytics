{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a651b99",
   "metadata": {},
   "source": [
    "# Tools for comparing transcript to each other\n",
    "For example when using different transcription tools, the outputs can be compared for multiple metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dfde8",
   "metadata": {},
   "source": [
    "# 1.Libraries and packages needed\n",
    "\n",
    "# Install core scientific & notebook packages via conda\n",
    "conda install -c conda-forge ipykernel nltk scikit-learn ipywidgets tqdm numpy scipy pandas\n",
    "\n",
    "# Use pip for sentence-transformers\n",
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd597f19",
   "metadata": {},
   "source": [
    "1. Word-by-Word Diff Report (transcript vs transcript)\n",
    "Use difflib to generate a clear markup of added/removed words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import ndiff\n",
    "\n",
    "# Load files\n",
    "with open(\"transcript_human.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    human_text = f.read()\n",
    "\n",
    "with open(\"transcript_whisper.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    whisper_text = f.read()\n",
    "\n",
    "# Word-level diff\n",
    "diff = list(ndiff(human_text.split(), whisper_text.split()))\n",
    "\n",
    "# Create HTML report\n",
    "html = \"<html><body><pre>\"\n",
    "for word in diff:\n",
    "    if word.startswith(\"- \"):\n",
    "        html += f\"<span style='color:red;'>[{word[2:]}]</span> \"\n",
    "    elif word.startswith(\"+ \"):\n",
    "        html += f\"<span style='color:green;'>{{{word[2:]}}}</span> \"\n",
    "    else:\n",
    "        html += word[2:] + \" \"\n",
    "html += \"</pre></body></html>\"\n",
    "\n",
    "# Save it\n",
    "with open(\"text_diff_report.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "print(\"âœ… HTML diff report saved as text_diff_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403cb3a",
   "metadata": {},
   "source": [
    "2. Semantic Chunk Comparison (Are the ideas the same?)\n",
    "Break both files into sentences and compare sentence similarity using Sentence-BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Load files\n",
    "with open(\"transcript_human.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    human_sentences = sent_tokenize(f.read())\n",
    "\n",
    "with open(\"transcript_whisper.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    whisper_sentences = sent_tokenize(f.read())\n",
    "\n",
    "# Embed and compare\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "emb_human = model.encode(human_sentences, convert_to_tensor=True)\n",
    "emb_whisper = model.encode(whisper_sentences, convert_to_tensor=True)\n",
    "\n",
    "# Pairwise comparisons\n",
    "for i, sent_h in enumerate(human_sentences):\n",
    "    sims = util.cos_sim(emb_human[i], emb_whisper)\n",
    "    best_idx = sims.argmax()\n",
    "    best_score = sims[0][best_idx].item()\n",
    "    if best_score < 0.85:\n",
    "        print(f\"\\nðŸ”»Low similarity ({best_score:.2f})\")\n",
    "        print(f\"Human:   {sent_h}\")\n",
    "        print(f\"Whisper: {whisper_sentences[best_idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ee587",
   "metadata": {},
   "source": [
    "3. Text Overlap Metrics (Quick summary stats)\n",
    "Use sklearn to get cosine similarity from TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5dd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load\n",
    "with open(\"transcript_human.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    human = f.read()\n",
    "with open(\"transcript_whisper.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    whisper = f.read()\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vec = TfidfVectorizer().fit_transform([human, whisper])\n",
    "sim = cosine_similarity(vec[0], vec[1])\n",
    "\n",
    "print(f\"ðŸ§  Cosine similarity (TF-IDF): {sim[0][0]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
